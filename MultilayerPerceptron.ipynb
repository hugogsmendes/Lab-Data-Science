{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTomKXQj2psLwyPTP+eN/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hugogsmendes/Lab-Data-Science/blob/main/MultilayerPerceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w9E1e8er4-Ud"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de Ativação Sigmóide\n",
        "def sigmoid (z):\n",
        "  return 1.0/(1.0+np.exp(-z))"
      ],
      "metadata": {
        "id": "aqmrfeNHATdk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network (object):\n",
        "\n",
        "  def __init__(self, sizes):\n",
        "    self.num_layers = len(sizes) # Número de camadas\n",
        "    self.sizes = sizes # Número de neurônios em cada camada\n",
        "    self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "    self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "\n",
        "  def feedforward(self, a):\n",
        "    for b, w in zip (self.biases, self.weights):\n",
        "      a = sigmoid(np.dot(w, a) + b)\n",
        "    return a\n",
        "\n",
        "  def SGD (self, training_data: list[tuple], epochs, mini_batch_size, eta, test_data=None):\n",
        "\n",
        "    training_data = list(training_data)\n",
        "    n = len(training_data)\n",
        "\n",
        "    if test_data:\n",
        "      test_data = list(test_data)\n",
        "      n_test = len(test_data)\n",
        "\n",
        "    for j in range(epochs):\n",
        "      random.shuffle(training_data)\n",
        "      mini_batches = [\n",
        "          training_data[k:k+mini_batch_size]\n",
        "          for k in range(0, n, mini_batch_size)]\n",
        "      for mini_batch in mini_batches:\n",
        "        self.update_mini_batch(mini_batch, eta)\n",
        "      if test_data:\n",
        "        print(f\"Epoch {j} : {self.evaluate(test_data)} / {n_test}\")\n",
        "      else:\n",
        "        print(f\"Epoch {j} complete\")"
      ],
      "metadata": {
        "id": "-I3up28h5alS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFeJgd8iK4Nz"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}